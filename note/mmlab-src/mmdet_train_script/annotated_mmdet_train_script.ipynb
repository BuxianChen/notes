{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mmdet 训练脚本解析\n",
    "版本号：\n",
    "- mmdet 2.18.0\n",
    "- mmcv 1.3.16\n",
    "- 1.7.0 <= pytorch < 1.9.0\n",
    "\n",
    "mmdetection 目录结构如下\n",
    "```\n",
    "mmdetection\n",
    "  - mmdet\n",
    "  - tools\n",
    "    - train.py\n",
    "    - dist_train.sh\n",
    "  - configs\n",
    "    - faster_rcnn\n",
    "      - faster_rcnn_r50_fpn_1x_coco.py\n",
    "  - work_dirs\n",
    "```\n",
    "完整的训练脚本参见 `train.py`，此脚本代码结构如下：\n",
    "```python\n",
    "import ...\n",
    "def parse_args():\n",
    "    ...\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "train.py 脚本的启动方式有两种：DP（Data Parallel）启动与DDP（Distributed Data Parallel）启动：\n",
    "\n",
    "**DP启动**\n",
    "``` bash\n",
    "python tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py <more_args>\n",
    "```\n",
    "**DDP启动**\n",
    "```\n",
    "# 一般会使用 dist_train.sh 脚本，例如单机4卡启动：\n",
    "# bash dist_train.sh configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py 4\n",
    "# 最终转换为如下方式启动\n",
    "python -m torch.distributed.launch --nproc_per_node=4 --master_port=29500 tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py --launcher pytorch <more_args>\n",
    "```\n",
    "为了理解这两种启动方式，应该先看看 `parse_args` 函数的具体细节，其源代码及注释如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from mmcv import DictAction\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train a detector')\n",
    "    # config文件名\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    # 存储日志及模型checkpoint的目录（相对于启动时的当前路径）\n",
    "    # 若不传，则默认将这个目录设定为\"./work_dirs/faster_rcnn_r50_fpn_1x_coco\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    # checkpoint路径，表示从该checkpoint继续训练，不传则表示从头训练\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    # 是否在训练时进行验证，默认进行验证\n",
    "    parser.add_argument(\n",
    "        '--no-validate',\n",
    "        action='store_true',\n",
    "        help='whether not to evaluate the checkpoint during training')\n",
    "    # 只能传 --gpus 与 --gpus-ids 参数至多一个，只适用于 DP 启动\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    \n",
    "    # 随机数种子\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    # 若传入，则表示 torch.backends.cudnn.benchmark=True\n",
    "    # 这一设定会让pytorch采用确定性算法计算卷积\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    \n",
    "    # 在命令行可以通过传入 --options（目前已被弃用） 或 --cfg-options\n",
    "    # 参数覆盖掉 config 文件（faster_rcnn_r50_fpn_1x_coco.py）中的一些参数\n",
    "    # 但一般不会传递这两个参数\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file (deprecate), '\n",
    "        'change to --cfg-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "\n",
    "    # 只讨论 none 与 pytorch 这两种情况\n",
    "    # none 对应的是 DP 启动，\n",
    "    # pytorch 对应的是 DDP 启动\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    \n",
    "    # DDP 训练时，必须要有这个参数，表示进程/GPU编号，\n",
    "    # 无需手动传递此参数，由torch.distributed.launch处理\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.cfg_options:\n",
    "        raise ValueError(\n",
    "            '--options and --cfg-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --cfg-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --cfg-options')\n",
    "        args.cfg_options = args.options\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，看 `main` 函数的具体内容：这里将 `main` 函数从上至下拆为如下几段进行解析：\n",
    "- （1）依据传入配置文件路径（configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py）及其他参数得到 `cfg`\n",
    "- （2）如果采用 DDP 方式训练，则需要进行一些初始化的工作\n",
    "- （3）配置日志文件，搜集环境信息放入变量 `meta` 中，这个信息最终会被保存在 checkpoint 中\n",
    "- （4）依据配置构建模型并初始化\n",
    "- （5）依据配置构建torch.utils.data.Dataset\n",
    "- （6）训练模型\n",
    "注意：前5个步骤都比较简单，较为复杂的是第6个步骤，需要再进行展开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（1）步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "cfg = Config.fromfile(args.config)\n",
    "if args.cfg_options is not None:\n",
    "    cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# 这一段使用了importlib的相关函数，动态导入cfg.custom_imports中用字符串表示的模块\n",
    "# 主要作用是\n",
    "# import modules from string list.\n",
    "if cfg.get('custom_imports', None):\n",
    "    from mmcv.utils import import_modules_from_strings\n",
    "    import_modules_from_strings(**cfg['custom_imports'])\n",
    "\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# work_dir is determined in this priority: CLI > segment in file > filename\n",
    "if args.work_dir is not None:\n",
    "    # update configs according to CLI args if args.work_dir is not None\n",
    "    cfg.work_dir = args.work_dir\n",
    "elif cfg.get('work_dir', None) is None:\n",
    "    # use config filename as default work_dir if cfg.work_dir is None\n",
    "    cfg.work_dir = osp.join('./work_dirs',\n",
    "                            osp.splitext(osp.basename(args.config))[0])\n",
    "if args.resume_from is not None:\n",
    "    cfg.resume_from = args.resume_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处需要解释的是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（2）步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DP 启动：**\n",
    "```bash\n",
    "python tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py \\\n",
    "--work-dir ./faster_rcnn_train gpu-ids 1,3 --seed 2 --deterministic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu_ids is not None:\n",
    "    cfg.gpu_ids = args.gpu_ids\n",
    "else:\n",
    "    cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "if args.launcher == 'none':\n",
    "    distributed = False\n",
    "else:\n",
    "    distributed = True\n",
    "    init_dist(args.launcher, **cfg.dist_params)\n",
    "    # re-set gpu_ids with distributed training mode\n",
    "    _, world_size = get_dist_info()\n",
    "    cfg.gpu_ids = range(world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（3）步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "# init the logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "meta['config'] = cfg.pretty_text\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# set random seeds\n",
    "if args.seed is not None:\n",
    "    logger.info(f'Set random seed to {args.seed}, '\n",
    "                f'deterministic: {args.deterministic}')\n",
    "    set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "cfg.seed = args.seed\n",
    "meta['seed'] = args.seed\n",
    "meta['exp_name'] = osp.basename(args.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（4）步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（5）步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    val_dataset.pipeline = cfg.data.train.pipeline\n",
    "    datasets.append(build_dataset(val_dataset))\n",
    "if cfg.checkpoint_config is not None:\n",
    "    # save mmdet version, config file content and class names in\n",
    "    # checkpoints as meta data\n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        mmdet_version=__version__ + get_git_hash()[:7],\n",
    "        CLASSES=datasets[0].CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第（6）步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "train_detector(\n",
    "    model,\n",
    "    datasets,\n",
    "    cfg,\n",
    "    distributed=distributed,\n",
    "    validate=(not args.no_validate),\n",
    "    timestamp=timestamp,\n",
    "    meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "import mmcv\n",
    "import time\n",
    "from mmdet.utils import collect_env, get_root_logger\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2082a01bff37d6a4c41da9c4c828fbb0b2d39dde0e254e556a9c64bdc607b76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
